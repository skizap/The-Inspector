# OpenAI API Key (Server-Side Only)
# This key is used by the serverless function (api/analyze.js) and is NOT exposed to the browser.
# DO NOT prefix with VITE_ as that would expose it to the browser (security risk).
# 
# For local development with Vercel CLI: vercel dev
# For deployment: Configure this in your Vercel project settings under Environment Variables
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Deployment Platform (Client-Side)
# Specifies which serverless function endpoint to use for OpenAI API calls.
# Values: "vercel" or "netlify"
# Default: "vercel" (if unset)
# 
# Set this to ensure correct endpoint routing:
# - Vercel deployments: VITE_DEPLOY_PLATFORM=vercel (or omit)
# - Netlify deployments: VITE_DEPLOY_PLATFORM=netlify
# - Local Netlify dev: VITE_DEPLOY_PLATFORM=netlify
# 
# Note: Auto-detection works on default Netlify subdomains (*.netlify.app)
# but may fail on custom domains. Setting this env var ensures deterministic routing.
VITE_DEPLOY_PLATFORM=vercel

# OpenAI Request Timeout (Client-Side, Optional)
# Overrides the default 30-second timeout for OpenAI API requests.
# Useful for Netlify deployments with shorter function timeout limits.
# Value in milliseconds.
# Default: 30000 (30 seconds)
# 
# Recommended values:
# - Vercel: 30000 (default, no override needed)
# - Netlify Free: 9000 (9 seconds, stay under 10s limit)
# - Netlify Pro: 25000 (25 seconds, stay under 26s limit)
# 
# Uncomment and set if needed:
# VITE_OPENAI_TIMEOUT=25000
